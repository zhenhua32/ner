# å‘½åå®ä½“è¯†åˆ«å®è·µä¸æ¢ç´¢

å®Œæ•´æ–‡æ¡£ï¼šhttps://zhuanlan.zhihu.com/p/166496466

æœ€è¿‘åœ¨åšå‘½åå®ä½“è¯†åˆ«ï¼ˆNamed Entity Recognition, NERï¼‰çš„å·¥ä½œï¼Œä¹Ÿå°±æ˜¯åºåˆ—æ ‡æ³¨ï¼ˆSequence Taggingï¼‰ï¼Œè€ NLP task äº†ï¼Œè™½ç„¶ä¹‹å‰ä¹Ÿåšè¿‡ä½†æ˜¯æƒ³ç»†è‡´åœ°æ‹ä¸€ä¸‹ï¼Œçœ‹ä¸€ä¸‹è‡ªä»æœ‰äº† LSTM+CRF ä¹‹åï¼ŒNER åœ¨åšäº›ä»€ä¹ˆï¼Œé¡ºä¾¿è®°å½•ä¸€ä¸‹æœ€è¿‘çš„å·¥ä½œï¼Œä¸­é—´æœ‰äº›ç»éªŒå’Œæƒ³æ³•ï¼Œæœ‰ä»€ä¹ˆå°±è®°ç‚¹ä»€ä¹ˆ

## è¿˜æ˜¯å…ˆæ”¾ç»“è®º

å‘½åå®ä½“è¯†åˆ«è™½ç„¶æ˜¯ä¸€ä¸ªå†å²æ‚ ä¹…çš„è€ä»»åŠ¡äº†ï¼Œä½†æ˜¯è‡ªä» 2015 å¹´æœ‰äººä½¿ç”¨äº† BI-LSTM-CRF æ¨¡å‹ä¹‹åï¼Œè¿™ä¸ªæ¨¡å‹å’Œè¿™ä¸ªä»»åŠ¡ç®€ç›´æ˜¯éƒæ‰å¥³è²Œï¼Œå¤©é€ åœ°è®¾ï¼Œè½®ä¸åˆ°ä»»ä½•å¦–æ€ªæ¥åå¯¹ã€‚ç›´åˆ°åæ¥å‡ºç°äº† BERTã€‚åœ¨è¿™é‡Œæ”¾ä¸¤ä¸ªé—®é¢˜ï¼š

1. 2015-2019 å¹´ï¼ŒBERT å‡ºç°ä¹‹å‰ 4 å¹´çš„æ—¶é—´ï¼Œå‘½åå®ä½“è¯†åˆ«å°±åªæœ‰ BI-LSTM-CRF äº†å—ï¼Ÿ
2. 2019 å¹´ BERT å‡ºç°ä¹‹åï¼Œå‘½åå®ä½“è¯†åˆ«å°±åªæœ‰ BERT-CRFï¼ˆæˆ–è€… BERT-LSTM-CRFï¼‰äº†å—ï¼Ÿ

ç»è¿‡æˆ‘ä¸å®Œå–„ä¹Ÿä¸æˆç†Ÿçš„è°ƒç ”ä¹‹åï¼Œå¥½åƒçš„ç¡®æ˜¯çš„ï¼Œä¸€ä¸ªèƒ½æ‰“çš„éƒ½æ²¡æœ‰

æ—¢ç„¶æ¨¡å‹æ‰“ä¸åŠ¨äº†ï¼Œç„¶åæˆ‘æ‰¾äº†æ‰¾ ACL2020 åš NER çš„è®ºæ–‡ï¼Œçœ‹çœ‹ç°åœ¨çš„ NER è¿˜åœ¨åšå“ªäº›äº‹æƒ…ï¼Œä¸»è¦åˆ†å‡ ä¸ªæ–¹é¢

- å¤šç‰¹å¾ï¼šå®ä½“è¯†åˆ«ä¸æ˜¯ä¸€ä¸ªç‰¹åˆ«å¤æ‚çš„ä»»åŠ¡ï¼Œä¸éœ€è¦å¤ªæ·±å…¥çš„æ¨¡å‹ï¼Œé‚£ä¹ˆå°±æ˜¯åŠ ç‰¹å¾ï¼Œç‰¹å¾è¶Šå¤šæ•ˆæœè¶Šå¥½ï¼Œæ‰€ä»¥å­—ç‰¹å¾ã€è¯ç‰¹å¾ã€è¯æ€§ç‰¹å¾ã€å¥æ³•ç‰¹å¾ã€KG è¡¨å¾ç­‰ç­‰çš„å°±ä¸€ä¸ªä¸ªåŠ å§ï¼Œç”šè‡³æœ‰äº›ä¸­æ–‡ NER ä»»åŠ¡é‡Œè¿˜åŠ å…¥äº†æ‹¼éŸ³ç‰¹å¾ã€ç¬”ç”»ç‰¹å¾ã€‚ã€‚ï¼Ÿå¿ƒæœ‰å¤šå¤§ï¼Œç‰¹å¾å°±æœ‰å¤šå¤š
- å¤šä»»åŠ¡ï¼šå¾ˆå¤šæ—¶å€™åš NER çš„ç›®çš„å¹¶ä¸ä»…æ˜¯ä¸ºäº† NERï¼Œè€Œæ˜¯ä¸€ä¸ªå¤§ä»»åŠ¡ä¸‹çš„å­ä»»åŠ¡ï¼Œæ¯”å¦‚ä¿¡æ¯æŠ½å–ã€é—®ç­”ç³»ç»Ÿç­‰ç­‰çš„ï¼Œå¦‚æœè¦åšä¸€ä¸ªç«¯åˆ°ç«¯çš„æ¨¡å‹ï¼Œé‚£ä¹ˆå°±éœ€è¦æ ¹æ®è‡ªå·±çš„éœ€æ±‚å’Œåœºæ™¯ï¼Œåšæˆä¸€ä¸ªå¤šä»»åŠ¡æ¨¡å‹ï¼ŒæŠŠ NER ä½œä¸ºå…¶ä¸­ä¸€ä¸ªå­ä»»åŠ¡ï¼›å¦å¤–ï¼Œå•ç‹¬çš„ NER æœ¬èº«ä¹Ÿå¯ä»¥åšæˆå¤šä»»åŠ¡ï¼Œæ¯”å¦‚ä¸€ä¸ªç”¨æ¥è¯†åˆ«å®ä½“ï¼Œä¸€ä¸ªç”¨æ¥åˆ¤æ–­å®ä½“ç±»å‹
- æ—¶ä»¤å¤§æ‚çƒ©ï¼šæŠŠå½“ä¸‹æ¯”è¾ƒæµè¡Œçš„æ·±åº¦å­¦ä¹ è¯é¢˜æˆ–æ–¹æ³•è·Ÿ NER ç»“åˆä¸€ä¸‹ï¼Œæ¯”å¦‚ç»“åˆå¼ºåŒ–å­¦ä¹ çš„ NERã€ç»“åˆ few-shot learning çš„ NERã€ç»“åˆå¤šæ¨¡æ€ä¿¡æ¯çš„ NERã€ç»“åˆè·¨è¯­ç§å­¦ä¹ çš„ NER ç­‰ç­‰çš„ï¼Œå…·ä½“å°±ä¸æäº†

æ‰€ä»¥æ²¿ç€ä¸Šè¿°æ€è·¯ï¼Œå°±åœ¨ä¸€ä¸ªä¸­æ–‡ NER ä»»åŠ¡ä¸Šåšä¸€äº›å®è·µï¼Œå†™ä¸€äº›æ¨¡å‹ã€‚éƒ½åˆ—åœ¨ä¸‹é¢äº†ï¼Œé¦–å…ˆæ˜¯ LSTM-CRF å’Œ BERT-CRFï¼Œç„¶å Cascade å¼€å¤´çš„æ˜¯å‡ ä¸ªå¤šä»»åŠ¡æ¨¡å‹ï¼ˆå› ä¸ºå®ä½“ç±»å‹æ¯”è¾ƒå¤šï¼ŒæŠŠ NER æ‹†æˆä¸¤ä¸ªä»»åŠ¡ï¼Œä¸€ä¸ªç”¨æ¥è¯†åˆ«å®ä½“ï¼Œå¦ä¸€ä¸ªç”¨æ¥åˆ¤æ–­å®ä½“ç±»å‹ï¼‰ï¼Œåé¢çš„å‡ ä¸ªæ¨¡å‹é‡Œï¼ŒWLF æŒ‡çš„æ˜¯ Word Level Featureï¼ˆå³åœ¨åŸæœ¬å­—çº§åˆ«çš„åºåˆ—æ ‡æ³¨ä»»åŠ¡ä¸ŠåŠ å…¥è¯çº§åˆ«çš„è¡¨å¾ï¼‰ï¼ŒWOL æŒ‡çš„æ˜¯ Weight of Lossï¼ˆå³åœ¨ loss å‡½æ•°æ–¹é¢é€šè¿‡è®¾ç½®æƒé‡æ¥æƒè¡¡ Precision ä¸ Recallï¼Œä»¥è¾¾åˆ°æé«˜ F1 çš„ç›®çš„ï¼‰

![](https://pic2.zhimg.com/80/v2-3062da7d38adce1213af496239f04bd9_720w.jpg)

# å…³äºæ•°æ®é›†

**è¿™ä¸ªåŸå§‹ git é‡Œçš„æ•°æ®é›†è´¨é‡ä¸è¡Œ, ä¸èƒ½ç”¨**, åªèƒ½è·‘èµ·æ¥è€Œå·². åŸä½œè€…çš„çŸ¥ä¹æ–‡ç« é‡Œä¹Ÿè¯´åˆ°äº†.

> ç¯å¢ƒï¼šPython3, Tensorflow1.12
>
> æ•°æ®ï¼šä¸€ä¸ªç”µå•†åœºæ™¯ä¸‹å•†å“æ ‡é¢˜ä¸­çš„å®ä½“è¯†åˆ«ï¼Œå› ä¸ºæ˜¯å·¥ä½œä¸­çš„æ•°æ®ï¼Œå¹¶ä¸”é€šè¿‡è¿œç¨‹ç›‘ç£å¼±æ ‡æ³¨çš„è´¨é‡ä¹Ÿä¸€èˆ¬ï¼Œå®Œæ•´æ•°æ®å°±ä¸æ”¾äº†ã€‚ä½†æ˜¯æˆ‘ sample äº†ä¸€äº›æ•°æ®ç•™åœ¨ git é‡Œäº†ï¼Œä¸ºäº†ç›´æ¥ git clone å®Œï¼Œä»£ç åŸåœ°å°±èƒ½è·‘ï¼Œæ–¹ä¾¿ä½ æˆ‘ä»–

# å¤åˆ»

åŸå§‹ä»£ç æ˜¯ç”¨ Tensorflow1.12 å®ç°çš„.
ç”¨ pytorch å’Œ tensorflow 2 é‡æ–°å®ç°.

å…ˆä»æœ€ç®€å•çš„å¼€å§‹å®ç°.

- [] BiLSTM
- [] BiLSTM + CRF

# å¯¼å‡ºæˆ onnx æ¨¡å‹

```bash
python -m tf2onnx.convert --checkpoint model.ckpt.batch8.meta --output model.onnx --inputs inputs_seq:0,inputs_seq_len:0 --outputs projection/dense/kernel:0

python -m tf2onnx.convert --checkpoint model.ckpt.batch8.meta --output model.onnx --inputs inputs_seq:0,inputs_seq_len:0 --outputs projection/dense/BiasAdd:0,projection/Softmax:0,projection/transitions:0

python -m tf2onnx.convert --checkpoint model.ckpt.batch8.meta --output model.onnx --inputs inputs_seq:0,inputs_seq_len:0 --outputs projection/transitions:0,projection/Softmax:0,projection/cond_2/ReverseSequence:0
```

ç¯å¢ƒå˜é‡ LD_LIBRARY_PATH æ˜¯åŠ¨æ€åº“æŸ¥æ‰¾çš„è·¯å¾„.

```bash
spark-submit --conf spark.executorEnv.LD_LIBRARY_PATH=/usr/local/lib my_app.py
```

- [conda ä½¿ç”¨åŠ¨æ€é“¾æ¥åº“çš„å°ç§˜å¯†](https://zhuanlan.zhihu.com/p/101027069)
- [conda è™šæ‹Ÿç¯å¢ƒä¸­æ·»åŠ ä¸´æ—¶ç¯å¢ƒå˜é‡ LD_LIBRARY_PATH(è§£å†³/usr/lib/libstdc++.so.6: version `GLIBCXX_3.4.20â€™ not found)](https://blog.csdn.net/jillar/article/details/116494270)
- [ã€pytorchã€‘/libstdc++.so.6: version `CXXABI_1.3.11â€˜ not found](https://blog.csdn.net/answer3664/article/details/108648139)

```bash
libstdc++.so.6 cxxabi not found
strings /usr/lib/libstdc++.so.6 | grep CXXABI
strings /usr/lib64/libstdc++.so.6 | grep CXXABI
# å¯ä»¥æ£€æŸ¥ä¸‹è¿™å‡ ä¸ªè·¯å¾„ä¸‹çš„
```

å¯¼å‡ºæ—¶æœ‰æŠ¥é”™, å®Œæ•´çš„æ—¥å¿—å¦‚ä¸‹:

```log
rojection/transitions:0,projection/Softmax:0,projection/cond_2/ReverseSequence_1:0
C:\Anaconda3\envs\ner\lib\site-packages\tensorflow\python\framework\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
C:\Anaconda3\envs\ner\lib\site-packages\tensorflow\python\framework\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
C:\Anaconda3\envs\ner\lib\site-packages\tensorflow\python\framework\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
C:\Anaconda3\envs\ner\lib\site-packages\tensorflow\python\framework\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
C:\Anaconda3\envs\ner\lib\site-packages\tensorflow\python\framework\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
C:\Anaconda3\envs\ner\lib\site-packages\tensorflow\python\framework\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
C:\Anaconda3\envs\ner\lib\runpy.py:125: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour
  warn(RuntimeWarning(msg))
2023-06-28 21:28:10,189 - INFO - Using tensorflow=1.13.1, onnx=1.14.0, tf2onnx=1.14.0/8f8d49
2023-06-28 21:28:10,190 - INFO - Using opset <onnx, 15>
2023-06-28 21:28:10,568 - INFO - Computed 0 values for constant folding
2023-06-28 21:28:10,982 - ERROR - Tensorflow op [projection/cond_2/sub/Switch: Switch] is not supported
2023-06-28 21:28:10,983 - ERROR - Tensorflow op [projection/cond_2/Slice/Switch: Switch] is not supported
2023-06-28 21:28:10,986 - ERROR - Tensorflow op [projection/cond_2/ExpandDims_1/Switch: Switch] is not supported
2023-06-28 21:28:11,010 - ERROR - Unsupported ops: Counter({'Switch': 3})
2023-06-28 21:28:11,031 - INFO - Optimizing ONNX model
2023-06-28 21:28:11,955 - INFO - After optimization: Cast -12 (38->26), Concat -3 (12->9), Const -118 (154->36), Expand -2 (6->4), Gather +2 (3->5), Identity -19 (19->0), Reshape -9 (16->7), Squeeze -5 (11->6), Transpose -3 (9->6), Unsqueeze -9 (18->9)
2023-06-28 21:28:11,995 - INFO -
2023-06-28 21:28:11,995 - INFO - Successfully converted TensorFlow model model.ckpt.batch8.meta to ONNX
2023-06-28 21:28:11,996 - INFO - Model inputs: ['inputs_seq:0', 'inputs_seq_len:0']
2023-06-28 21:28:11,996 - INFO - Model outputs: ['projection/transitions:0', 'projection/Softmax:0', 'projection/cond_2/ReverseSequence_1:0']
2023-06-28 21:28:11,996 - INFO - ONNX model is saved at model.onnx
```

`Switch] is not supported` ä¼°è®¡æ˜¯å› ä¸º crf è§£ç æ—¶æœ‰ä¸ªæ¡ä»¶åˆ¤æ–­.

ç„¶åç”¨ ONNX æ¨ç†å°±ä¼šæŠ¥é”™, åŠ è½½æ¨¡å‹æ—¶å°±å‡ºé”™äº†.

```log
Traceback (most recent call last):
  File ".\predict.py", line 4, in <module>
    session = onnxruntime.InferenceSession('./ckpt/model.onnx')
  File "C:\Anaconda3\envs\ner\lib\site-packages\onnxruntime\capi\onnxruntime_inference_collection.py", line 360, in __init__
    self._create_inference_session(providers, provider_options, disabled_optimizers)
  File "C:\Anaconda3\envs\ner\lib\site-packages\onnxruntime\capi\onnxruntime_inference_collection.py", line 397, in _create_inference_session
    sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)
onnxruntime.capi.onnxruntime_pybind11_state.InvalidGraph: [ONNXRuntimeError] : 10 : INVALID_GRAPH : Load model from ./ckpt/model.onnx failed:This is an invalid model. In Node, ("projection/cond_2/ExpandDims_1/Switch", Switch, "", -1) : ("projection/transitions:0": tensor(float),"projection/Equal_2:0": tensor(bool),) -> ("projection/cond_2/ExpandDims_1/Switch:0","projection/cond_2/ExpandDims_1/Switch:1",) , Error No Op registered for Switch with domain_version of 15
```

# ç”¨ numpy å®ç° crf decode

æ‚¨å¥½ï¼Œæ„Ÿè°¢æ‚¨ä½¿ç”¨å¿…åº”æœç´¢ã€‚æ ¹æ®æ‚¨çš„æœç´¢è¯ï¼Œæˆ‘ä¸ºæ‚¨æ‰¾åˆ°äº†ä»¥ä¸‹ä¿¡æ¯ï¼š

## numpy crf decode

numpy crf decode æ˜¯æŒ‡åœ¨ numpy ä¸­ä½¿ç”¨æ¡ä»¶éšæœºåœºï¼ˆCRFï¼‰æ¨¡å‹è¿›è¡Œåºåˆ—æ ‡æ³¨ä»»åŠ¡çš„è§£ç è¿‡ç¨‹ã€‚CRF æ˜¯ä¸€ç§æ¦‚ç‡å›¾æ¨¡å‹ï¼Œå¯ä»¥ç”¨äºå»ºæ¨¡åºåˆ—æ•°æ®çš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒ Â¹ã€‚

è¦åœ¨ numpy ä¸­å®ç° crf decodeï¼Œæœ‰ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š

- æ­¥éª¤ä¸€ï¼šå®šä¹‰ CRF æ¨¡å‹çš„å‚æ•°ã€‚CRF æ¨¡å‹çš„å‚æ•°åŒ…æ‹¬çŠ¶æ€ç‰¹å¾æƒé‡çŸ©é˜µ W å’Œè½¬ç§»ç‰¹å¾æƒé‡çŸ©é˜µ Tã€‚W çš„å½¢çŠ¶ä¸º (n_states, n_features)ï¼ŒT çš„å½¢çŠ¶ä¸º (n_states, n_states)ã€‚ä¾‹å¦‚ï¼š

```python
import numpy as np
n_states = 3 # number of possible tags
n_features = 4 # number of input features
W = np.random.randn(n_states, n_features) # state feature weights
T = np.random.randn(n_states, n_states) # transition feature weights
```

- æ­¥éª¤äºŒï¼šå®šä¹‰è¾“å…¥åºåˆ—çš„ç‰¹å¾çŸ©é˜µ X å’ŒçœŸå®æ ‡ç­¾åºåˆ— yã€‚X çš„å½¢çŠ¶ä¸º (n_steps, n_features)ï¼Œy çš„å½¢çŠ¶ä¸º (n_steps,)ã€‚ä¾‹å¦‚ï¼š

```python
n_steps = 5 # length of the input sequence
X = np.random.randn(n_steps, n_features) # input feature matrix
y = np.array([0, 1, 2, 1, 0]) # true label sequence
```

- æ­¥éª¤ä¸‰ï¼šå®šä¹‰ Viterbi ç®—æ³•çš„å‡½æ•°ã€‚Viterbi ç®—æ³•æ˜¯ä¸€ç§åŠ¨æ€è§„åˆ’ç®—æ³•ï¼Œå¯ä»¥ç”¨äºå¯»æ‰¾æœ€å¯èƒ½çš„æ ‡ç­¾åºåˆ— Â²ã€‚Viterbi ç®—æ³•çš„å‡½æ•°æ¥å— Wï¼ŒT å’Œ X ä½œä¸ºè¾“å…¥ï¼Œè¿”å›æœ€ä¼˜æ ‡ç­¾åºåˆ— y_pred å’Œæœ€å¤§å¯¹æ•°ä¼¼ç„¶å€¼ scoreã€‚ä¾‹å¦‚ï¼š

```python
def viterbi_decode(W, T, X):
    n_steps, n_features = X.shape
    n_states = W.shape[0]
    # Initialize the score matrix and the backpointer matrix
    score = np.zeros((n_steps, n_states))
    backpointer = np.zeros((n_steps, n_states), dtype=np.int32)
    # Compute the score and the backpointer for the first step
    score[0] = W.dot(X[0])
    backpointer[0] = -1
    # Loop over the remaining steps
    for i in range(1, n_steps):
        # Compute the score and the backpointer for the current step
        score[i] = W.dot(X[i]) + T + score[i-1][:, None]
        backpointer[i] = np.argmax(score[i], axis=0)
        # Normalize the score to avoid numerical issues
        score[i] -= np.max(score[i])
    # Trace back the optimal path from the last step
    y_pred = np.zeros(n_steps, dtype=np.int32)
    y_pred[-1] = np.argmax(score[-1])
    for i in range(n_steps-2, -1, -1):
        y_pred[i] = backpointer[i+1][y_pred[i+1]]
    # Return the optimal path and the maximum log-likelihood
    return y_pred, np.max(score[-1])
```

- æ­¥éª¤å››ï¼šè°ƒç”¨ Viterbi ç®—æ³•çš„å‡½æ•°ï¼Œå¾—åˆ°æœ€ä¼˜æ ‡ç­¾åºåˆ— y_pred å’Œæœ€å¤§å¯¹æ•°ä¼¼ç„¶å€¼ scoreã€‚ä¾‹å¦‚ï¼š

```python
y_pred, score = viterbi_decode(W, T, X)
print(y_pred)
print(score)
```

ä»¥ä¸‹æ˜¯ä¸€äº›ç›¸å…³çš„ç½‘é¡µé“¾æ¥ï¼š

- [NumPy decode() function - Studytonight](https://www.studytonight.com/numpy/numpy-decode-function)
- [numpy.char.decode â€” NumPy v1.25 Manual](https://numpy.org/doc/stable/reference/generated/numpy.char.decode.html)
- [numpy.chararray.decode â€” NumPy v1.25 Manual](https://numpy.org/doc/stable/reference/generated/numpy.chararray.decode.html)
- [æ¡ä»¶éšæœºåœºï¼ˆCRFï¼‰åŸç†åŠåº”ç”¨ - CSDN åšå®¢](https://blog.csdn.net/qq_16234613/article/details/79451511)
- [Viterbi ç®—æ³•è¯¦è§£ - CSDN åšå®¢](https://blog.csdn.net/qq_19707521/article/details/78479532)

å¸Œæœ›è¿™äº›ä¿¡æ¯å¯¹æ‚¨æœ‰å¸®åŠ©ã€‚å¦‚æœæ‚¨è¿˜æœ‰å…¶ä»–é—®é¢˜ï¼Œæ¬¢è¿ç»§ç»­ä½¿ç”¨å¿…åº”æœç´¢ã€‚ğŸ˜Š

æº: ä¸å¿…åº”çš„å¯¹è¯ï¼Œ 2023/6/28
(1) numpy.char.decode â€” NumPy v1.25 Manual. https://numpy.org/doc/stable/reference/generated/numpy.char.decode.html.
(2) numpy.chararray.decode â€” NumPy v1.25 Manual. https://numpy.org/doc/stable/reference/generated/numpy.chararray.decode.html.
(3) NumPy decode() function - Studytonight. https://www.studytonight.com/numpy/numpy-decode-function.

# spark --archives

æ‚¨å¥½ï¼Œæ„Ÿè°¢æ‚¨ä½¿ç”¨å¿…åº”æœç´¢ã€‚æ ¹æ®æ‚¨çš„æœç´¢è¯ï¼Œæˆ‘ä¸ºæ‚¨æ‰¾åˆ°äº†ä»¥ä¸‹ä¿¡æ¯ï¼š

## pyspark --archives

pyspark --archives æ˜¯æŒ‡åœ¨æäº¤ pyspark ä½œä¸šæ—¶ï¼Œä½¿ç”¨ --archives å‚æ•°æ¥ä¼ é€’ä¸€äº›å‹ç¼©æ–‡ä»¶ï¼Œè¿™äº›æ–‡ä»¶ä¼šè¢«è§£å‹åˆ°æ¯ä¸ªæ‰§è¡Œå™¨çš„å·¥ä½œç›®å½•ä¸­ã€‚æ”¯æŒçš„å‹ç¼©æ–‡ä»¶æ ¼å¼æœ‰ .jar, .tar.gz, .tgz å’Œ .zipã€‚æ‚¨å¯ä»¥é€šè¿‡åœ¨æ–‡ä»¶åååŠ  # æ¥æŒ‡å®šè§£å‹åçš„ç›®å½•åï¼Œä¾‹å¦‚ file.zip#directoryã€‚è¿™ä¸ªå‚æ•°æ˜¯å®éªŒæ€§çš„ï¼Œè‡ª Spark 3.1.0 ç‰ˆæœ¬å¼€å§‹æ”¯æŒ Â¹ã€‚

è¦åœ¨ pyspark ä¸­è·å– --archives ä¼ è¿‡æ¥çš„æ–‡ä»¶çš„è·¯å¾„ï¼Œæœ‰ä»¥ä¸‹å‡ ç§æ–¹æ³•ï¼š

- æ–¹æ³•ä¸€ï¼šä½¿ç”¨ SparkFiles æ¨¡å—æ¥è·å–æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ã€‚SparkFiles æ¨¡å—æä¾›äº†ä¸€ä¸ª get () å‡½æ•°ï¼Œå¯ä»¥æ ¹æ®æ–‡ä»¶åæˆ–ç›®å½•åæ¥è¿”å›æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ Â²ã€‚ä¾‹å¦‚ï¼š

```python
from pyspark import SparkFiles
# Suppose we submit the job with --archives file.zip#directory
file_path = SparkFiles.get("file.zip") # get the path of the zip file
dir_path = SparkFiles.get("directory") # get the path of the unzipped directory
```

- æ–¹æ³•äºŒï¼šä½¿ç”¨ os æ¨¡å—æ¥è·å–æ–‡ä»¶çš„ç›¸å¯¹è·¯å¾„ã€‚os æ¨¡å—æä¾›äº†ä¸€ä¸ª getcwd () å‡½æ•°ï¼Œå¯ä»¥è¿”å›å½“å‰å·¥ä½œç›®å½•çš„è·¯å¾„ Â³ã€‚ä¾‹å¦‚ï¼š

```python
import os
# Suppose we submit the job with --archives file.zip#directory
cwd = os.getcwd() # get the current working directory
file_path = os.path.join(cwd, "file.zip") # get the relative path of the zip file
dir_path = os.path.join(cwd, "directory") # get the relative path of the unzipped directory
```

ä»¥ä¸‹æ˜¯ä¸€äº›ç›¸å…³çš„ç½‘é¡µé“¾æ¥ï¼š

- [Configuration - Spark 3.4.1 Documentation - Apache Spark](https://spark.apache.org/docs/latest/configuration.html)
- [What's the difference between --archives, --files, py-files in pyspark ...](https://stackoverflow.com/questions/38066318/whats-the-difference-between-archives-files-py-files-in-pyspark-job-argum)
- [PySpark Archives - Spark By {Examples}](https://sparkbyexamples.com/category/pyspark/)

å¸Œæœ›è¿™äº›ä¿¡æ¯å¯¹æ‚¨æœ‰å¸®åŠ©ã€‚å¦‚æœæ‚¨è¿˜æœ‰å…¶ä»–é—®é¢˜ï¼Œæ¬¢è¿ç»§ç»­ä½¿ç”¨å¿…åº”æœç´¢ã€‚ğŸ˜Š

æº: ä¸å¿…åº”çš„å¯¹è¯ï¼Œ 2023/6/28
(1) What's the difference between --archives, --files, py-files in pyspark .... https://stackoverflow.com/questions/38066318/whats-the-difference-between-archives-files-py-files-in-pyspark-job-argum.
(2) Configuration - Spark 3.4.1 Documentation - Apache Spark. https://spark.apache.org/docs/latest/configuration.html.
(3) PySpark Archives - Spark By {Examples}. https://sparkbyexamples.com/category/pyspark/.

# pip list

```
Package              Version
-------------------- ---------
absl-py              1.4.0
appdirs              1.4.3
astor                0.8.1
attrs                23.1.0
black                19.10b0
certifi              2022.12.7
charset-normalizer   3.1.0
click                8.1.3
colorama             0.4.6
coloredlogs          15.0.1
flake8               3.7.9
flatbuffers          2.0.7
gast                 0.5.4
grpcio               1.56.0
h5py                 3.8.0
humanfriendly        10.0
idna                 3.4
importlib-metadata   6.7.0
Keras-Applications   1.0.8
Keras-Preprocessing  1.1.2
Markdown             3.4.3
MarkupSafe           2.1.3
mock                 5.0.2
mpmath               1.3.0
numpy                1.21.6
onnx                 1.14.0
onnxruntime          1.14.1
packaging            23.1
pathspec             0.7.0
pip                  22.3.1
protobuf             3.20.0
pyreadline           2.1
regex                2020.2.20
requests             2.31.0
setuptools           65.6.3
six                  1.16.0
sympy                1.10.1
tensorboard          1.13.1
tensorflow           1.13.1
tensorflow-estimator 1.13.0
termcolor            2.3.0
tf2onnx              1.14.0
toml                 0.10.0
typed-ast            1.4.1
typing_extensions    4.6.3
urllib3              2.0.3
Werkzeug             2.2.3
wheel                0.38.4
wincertstore         0.2
zipp                 3.15.0
```

